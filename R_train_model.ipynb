{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold,StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score,roc_auc_score, roc_curve, average_precision_score,precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\",80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set\n",
    "df = pd.read_csv('training_dataa/riyadh_training_set.csv')\n",
    "df = df.dropna(how='any',axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_fields=['one_way','surface_type','street_type','hour','weekday','month']\n",
    "\n",
    "# One-Hot encode a couple of variables\n",
    "df_ohe = pd.get_dummies(df,columns=ohe_fields)\n",
    "\n",
    "# Get the one-hot variable names\n",
    "ohe_feature_names = pd.get_dummies(df[ohe_fields],columns=ohe_fields).columns.tolist()\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinuosity is typically close to 1, even for moderately curvy roads. A high sinuosity means a longer road.\n",
    "feature_transforms = {\n",
    "    'sinuosity': np.log\n",
    "}\n",
    "for feature,transform in feature_transforms.items():\n",
    "    df_ohe[feature] = transform(df_ohe[feature])\n",
    "\n",
    "# Continuously valued features\n",
    "float_feature_names = [\n",
    "    'accident_counts',\n",
    "    'speed_limit',\n",
    "    'aadt',\n",
    "    'surface_width',\n",
    "    'sinuosity',\n",
    "    'euclidean_length',\n",
    "    'segment_length',\n",
    "    'road_orient_approx',\n",
    "    'Rain',\n",
    "    'dust',\n",
    "    'temperature',\n",
    "    'visibility',\n",
    "    'wind_speed',\n",
    "    'proximity_to_billboard',\n",
    "    'proximity_to_major_road',\n",
    "    'proximity_to_signal',\n",
    "    'proximity_to_nearest_intersection',\n",
    "    'proximity_to_nearest_exit',\n",
    "    'population_density',\n",
    "    'Hopspot',\n",
    "    'solar_azimuth',\n",
    "    'solar_elevation',\n",
    "]\n",
    "float_features = df_ohe.xs(float_feature_names,axis=1).values\n",
    "\n",
    "# Use scikit-learn's StandardScaler\n",
    "scaler = StandardScaler()\n",
    "float_scaled = scaler.fit_transform(float_features)\n",
    "#print (float_features.mean(axis=0))\n",
    "\n",
    "df_ohe[float_feature_names] = float_scaled\n",
    "\n",
    "with open('scalers.pkl','wb') as fp:\n",
    "    pickle.dump(scaler,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target'].values\n",
    "\n",
    "binary_feature_names = [\n",
    "    'extreme_air_temperature',\n",
    "    'dew_point_temperature',\n",
    "    'sky_cover_layer',\n",
    "    'at_exit',\n",
    "    'at_intersection',\n",
    "]\n",
    "\n",
    "df_ohe = df_ohe.xs(float_feature_names+binary_feature_names+ohe_feature_names,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ohe.values\n",
    "y = df['target'].values\n",
    "feature_names = df_ohe.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangler = {\n",
    "    'scaler': scaler,\n",
    "    'float_scaler_std': float_scaled,\n",
    "    'float_feature_names': float_feature_names,\n",
    "    'ohe_fields': ohe_fields,\n",
    "    'feature_names': feature_names,\n",
    "    'feature_transforms': feature_transforms \n",
    "}\n",
    "with open('wrangler.pkl','wb') as fp:\n",
    "    pickle.dump(wrangler,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sel = range(len(feature_names))\n",
    "#feature_sel = [-1,-2,-3]\n",
    "Xs = X[:,feature_sel]\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.1)#, random_state=2)\n",
    "fnames = np.array(feature_names)[feature_sel]\n",
    "\n",
    "dtrain = xgboost.DMatrix(X_train,label=y_train,feature_names=fnames)\n",
    "dtest =  xgboost.DMatrix(X_test,label=y_test,feature_names=fnames)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 5.0,\n",
    "    'reg_lambda': 1.0,\n",
    "    'reg_alpha':0.0,\n",
    "    'scale_pos_weight':1.0,\n",
    "    'eval_metric':'auc',\n",
    "    'objective':'binary:logistic',\n",
    "    'eta':0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xgboost.train(params,dtrain,\n",
    "    evals = [(dtest, 'eval')],\n",
    "    num_boost_round=3000,\n",
    "    early_stopping_rounds=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "xgboost.plot_importance(booster,ax=plt.gca(),importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster.save_model('new_0001.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = booster.predict(dtest)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred_test)\n",
    "\n",
    "y_pred_train = booster.predict(dtrain)\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train,y_pred_train)\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot([0,1],[0,1],'r-',label='Random Guess',color='orange',lw=3)\n",
    "plt.plot(fpr,tpr,label='ROC (Test)',lw=3)\n",
    "plt.plot(fpr_train,tpr_train,'r:',label='ROC (Train)',color='steelblue',lw=3)\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds,tpr,'r-',label='TPR (Test)',color='orange',lw=3)\n",
    "plt.plot(thresholds_train,tpr_train,'r:',label='TPR (Train',color='orange',lw=3)\n",
    "plt.plot(thresholds,fpr,'r-',label='FPR (Test)',color='steelblue',lw=3)\n",
    "plt.plot(thresholds_train,fpr_train,'r:',label='FPR (Train)',color='steelblue',lw=3)\n",
    "plt.gca().set_xbound(lower=0,upper=1)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('True/False Positive Rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "y_pred_test = booster.predict(dtest)\n",
    "y_pred_train = booster.predict(dtrain)\n",
    "\n",
    "precision,recall,thresholds = precision_recall_curve(y_test,y_pred_test)\n",
    "precision_train, recall_train, thresholds_train = precision_recall_curve(y_train,y_pred_train)\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot(precision,recall,label='PR (Test)',lw=3)\n",
    "plt.plot(precision_train,recall_train,label='PR (Train)',lw=3)\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds,precision[:-1],'r-',label='P (Test)',color='orange',lw=3)\n",
    "plt.plot(thresholds_train,precision_train[:-1],'r:',label='P (Train',color='orange',lw=3)\n",
    "plt.plot(thresholds,recall[:-1],'r-',label='R (Test)',color='steelblue',lw=3)\n",
    "plt.plot(thresholds_train,recall_train[:-1],'r:',label='R (Train)',color='steelblue',lw=3)\n",
    "#plt.plot([0,1],[0,1],'k-',lw=2)\n",
    "plt.gca().set_xbound(lower=0,upper=1)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision/Recall')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = booster.predict(dtest) > 0.19\n",
    "print ('Test Accuracy:',accuracy_score(y_test,y_pred_test))\n",
    "print ('Test F1:',f1_score(y_test,y_pred_test))\n",
    "print ('Test Precision:',precision_score(y_test,y_pred_test))\n",
    "print ('Test Recall:',recall_score(y_test,y_pred_test))\n",
    "y_pred_test = booster.predict(dtest)\n",
    "print ('Test AUC:',roc_auc_score(y_test,y_pred_test))\n",
    "print ('Test AP:',average_precision_score(y_test,y_pred_test))\n",
    "\n",
    "y_pred_train = booster.predict(dtrain) > 0.19\n",
    "print ('Train Accuracy:',accuracy_score(y_train,y_pred_train))\n",
    "print ('Train F1:',f1_score(y_train,y_pred_train))\n",
    "print ('Train Precision:',precision_score(y_train,y_pred_train))\n",
    "print ('Train Recall:',recall_score(y_train,y_pred_train))\n",
    "y_pred_train = booster.predict(dtrain)\n",
    "print ('Train AUC:',roc_auc_score(y_train,y_pred_train))\n",
    "print ('Test AP:',average_precision_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_split_histogram(feature_name):\n",
    "    hist = booster.get_split_value_histogram(feature_name)\n",
    "    try:\n",
    "        i = float_feature_names.index(feature_name)\n",
    "        fake_data = np.zeros((hist.Count.size,len(float_feature_names)))\n",
    "        fake_data[:,i] = hist.SplitValue\n",
    "        hist.loc[:,'SplitValue'] = scaler.inverse_transform(fake_data)[:,i]\n",
    "    except: pass\n",
    "    hist.plot(kind='area',x='SplitValue',y='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_split_histogram('temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_split_histogram('solar_azimuth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_split_histogram('solar_elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_split_histogram('proximity_to_billboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_split_histogram('population_density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_split_histogram('sinuosity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import pytz\n",
    "import arcgis\n",
    "#\n",
    "#plotting\n",
    "#'''\n",
    "from IPython.display import HTML, display\n",
    "import datashader as ds\n",
    "from datashader import transfer_functions as tf\n",
    "from datashader.colors import colormap_select, Greys9, Hot, viridis, inferno\n",
    "#'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import matplotlib as mpl\n",
    "mpl.rc('xtick', color='k')\n",
    "mpl.rc('ytick', color='k')\n",
    "%matplotlib inline\n",
    "#'''\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wrangler.pkl','rb') as fp:\n",
    "    wrangler = pickle.load(fp)\n",
    "\n",
    "float_scaler_mean = wrangler['scaler']\n",
    "float_scaler_std = wrangler['float_scaler_std']\n",
    "float_feature_names = wrangler['float_feature_names']\n",
    "ohe_fields = wrangler['ohe_fields']\n",
    "feature_names = wrangler['feature_names']   \n",
    "booster = xgboost.Booster()\n",
    "booster.load_model('new_0001.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_gdb = r'D:\\Model_R\\Model_RT\\Model_RT.gdb'\n",
    "collisions_path = os.path.join(project_gdb,'collisions_joined_1')\n",
    "road_features_path = os.path.join(project_gdb,'SRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_tz = pytz.timezone('Asia/Riyadh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_features = pd.read_csv('training_dataa/road_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions =  pd.read_csv('training_dataa/collisions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidx = pd.DatetimeIndex(collisions['timestamp']).floor('H')\n",
    "tidx = tidx.tz_localize(R_tz,ambiguous='NaT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collisions['timestamp'] = pd.to_datetime(collisions.timestamp).map(utah_tz.localize)\n",
    "collisions = collisions.set_index(tidx)\n",
    "collisions.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions['hour'] = collisions.index.hour\n",
    "collisions['weekday'] = collisions.index.weekday\n",
    "collisions['month'] = collisions.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf = pd.read_csv('Riyadh_weather_2014-2019_grouped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf['timestamp'] = pd.to_datetime(wdf.timestamp).map(pytz.utc.localize)\n",
    "wdf['timestamp'] = wdf['timestamp'].map(lambda x: x.astimezone(R_tz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf = wdf.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString, Point, box, mapping\n",
    "import ast\n",
    "from pyproj import Proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = road_features.SHAPE.map(lambda x: np.array(ast.literal_eval(x)['paths'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathLineStrings = paths.map(LineString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(road_features,geometry=pathLineStrings)\n",
    "gdf.crs = {'init': 'epsg:32638'}\n",
    "#gdf.crs = {'init': 'epsg:4326'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.to_crs({'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 900714804574\n",
    "x1 = -5120900\n",
    "y0 = 900709927374\n",
    "y1 = -9998100\n",
    "SLC = box(x0,y0,x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc_df = gdf[gdf.intersects(SLC)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10,10))\n",
    "#help(gdf.plot)\n",
    "slc_df['scaled'] = slc_df['accident_counts']\n",
    "slc_df.plot(ax=ax,column='scaled',scheme='quantiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTimest = pd.date_range('5/22/2016', periods=7*24, freq='H',tz='Asia/Riyadh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTimest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_time = predTimest[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = slc_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['timestamp'] = prediction_time\n",
    "test_df['station_id'] = slc_df.station_id.astype('int64')\n",
    "test_df['hour'] = prediction_time.hour\n",
    "test_df['weekday'] = prediction_time.weekday()\n",
    "test_df['month'] = prediction_time.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_join_key(df):\n",
    "    df['join_key'] = df.station_id.map(int).map(str)+df.timestamp.map(datetime.datetime.isoformat)\n",
    "    df = df.set_index('join_key')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weath_df = wdf.loc[prediction_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = add_join_key(test_df)\n",
    "weath_df = add_join_key(weath_df.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.join(weath_df.drop(columns=['station_id','timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_set(df,wrangler):\n",
    "    float_scaler_mean = wrangler['scaler']\n",
    "    float_scaler_std = wrangler['float_scaler_std']\n",
    "    float_feature_names = wrangler['float_feature_names']\n",
    "    ohe_fields = wrangler['ohe_fields']\n",
    "    feature_names = wrangler['feature_names'] \n",
    "    print(len(feature_names))\n",
    "    df_ohe = pd.get_dummies(df,columns=ohe_fields)\n",
    "\n",
    "    float_features = df.xs(float_feature_names,axis=1).values\n",
    "    float_features = (float_features - float_scaler_mean) / float_scaler_std\n",
    "    for i,fname in enumerate(float_feature_names):\n",
    "        df_ohe[fname] = float_features[:,i]\n",
    "        \n",
    "    empty_features = list(set(feature_names) - set(df_ohe.columns.tolist()))\n",
    "    for f in empty_features:\n",
    "        df_ohe[f] = 0\n",
    "    df_ohe = df_ohe[feature_names]\n",
    "    \n",
    "    #print(df_ohe.columns)\n",
    "    #print(df_ohe.columns.tolist())\n",
    "    X = df_ohe.values\n",
    "    feature_names = df_ohe.columns.tolist()\n",
    "    return X, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as c\n",
    "help(c.LinearSegmentedColormap.from_list)\n",
    "cmap = c.LinearSegmentedColormap.from_list('traffic',['g','g','g','y','orange','r','darkred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "%matplotlib\n",
    "fig,ax = plt.subplots()\n",
    "for i,pt in enumerate(predTimest[:72]):\n",
    "    test_df = slc_df.copy()\n",
    "    test_df['timestamp'] = pt\n",
    "    test_df['station_id'] = slc_df.station_id.astype('int64')\n",
    "    test_df['hour'] = prediction_time.hour\n",
    "    test_df['weekday'] = prediction_time.weekday()\n",
    "    test_df['month'] = prediction_time.month\n",
    "    \n",
    "    weath_df = wdf.loc[pt]\n",
    "    test_df = add_join_key(test_df)\n",
    "    weath_df = add_join_key(weath_df.reset_index())\n",
    "    \n",
    "    test_df = test_df.join(weath_df.drop(columns=['station_id','timestamp']))\n",
    "    X,names = make_test_set(test_df,wrangler)\n",
    "    xm = xgboost.DMatrix(X[:,:],feature_names=names)\n",
    "    \n",
    "    pred = booster.predict(xm)\n",
    "    test_df['probability'] = np.minimum(pred,0.50)\n",
    "    test_collisions = collisions[(pt - datetime.timedelta(seconds=0)).isoformat():(pt + datetime.timedelta(seconds=3600)).isoformat()]\n",
    "    fig,ax = plt.subplots()\n",
    "    \n",
    "    fig.set_size_inches((15,15))\n",
    "    test_df.plot(ax=ax,column='probability',cmap=cmap,linewidth=3,alpha=1)\n",
    "    plt.gca().set_facecolor('k')\n",
    "    #plt.imshow(np.array([[test_df.probability.min(),test_df.probability.max()]]),origin='lower')\n",
    "    test_collisions.plot.scatter(x='DDLon',y='DDLat',ax=ax,s=100,marker='*',color='r',zorder=6e99)\n",
    "    ax.set_xbound(lower=x0,upper=x1)\n",
    "    ax.set_ybound(lower=y0,upper=y1)\n",
    "    #plt.colorbar()\n",
    "    plt.savefig('{}.png'.format(i))\n",
    "   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,names = make_test_set(test_df,wrangler)\n",
    "print (X.shape)\n",
    "print (X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = xgboost.DMatrix(X[:,:],feature_names=names[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = booster.predict(xm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(pred,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['probability'] = pred*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_collisions = collisions[(prediction_time - datetime.timedelta(seconds=0)).isoformat():(prediction_time + datetime.timedelta(seconds=3600)).isoformat()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['vis'] = np.log(test_df['probability']) - np.log( test_df.geometry.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['probability'] = np.minimum(pred,0.08)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "fig.set_size_inches((15,15))\n",
    "test_df.plot(ax=ax,column='probability',cmap=cmap)\n",
    "plt.gca().set_facecolor('k')\n",
    "plt.imshow(np.array([[test_df.probability.min(),test_df.probability.max()]]),origin='lower',cmap=cmap)\n",
    "test_collisions.plot.scatter(x='Longitude',y='Latitude',\n",
    "                             ax=ax,\n",
    "                             s=500,\n",
    "                             color='w',\n",
    "                             zorder=9e99,\n",
    "                             marker='*',\n",
    "                             edgecolors='r')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "ax.set_xbound(lower=x0,upper=x1)\n",
    "ax.set_ybound(lower=y0,upper=y1)\n",
    "plt.colorbar(cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[:,'timestamp'] = test_df.loc[:,'timestamp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_file('Riyadh_probability.shp', driver='ESRI Shapefile')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
